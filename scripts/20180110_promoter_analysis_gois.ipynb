{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what computer are you on? a = Bens, b = gpucluster, c = other   b\n",
      "base directory is /home/heineike/github/expression_broad_data\n",
      "I am about to import a library\n",
      "I am importing io_library\n",
      "what computer are you on? a = Bens, b = gpucluster, c = other   b\n",
      "base directory is /home/heineike/github/expression_broad_data\n",
      "data processing dir is /home/heineike/github/expression_broad_data/expression_data/\n",
      "are you online? Yes/NoYes\n"
     ]
    }
   ],
   "source": [
    "# %load std_libraries.py\n",
    "import sys\n",
    "#Indicate operating environment and import core modules\n",
    "location_input = input(\"what computer are you on? a = Bens, b = gpucluster, c = other   \")\n",
    "location_dict = {'a': \"C:\\\\Users\\\\heine\\\\github\\\\expression_broad_data\", 'b': \"/home/heineike/github/expression_broad_data\",'c':'you need to add your location to the location_dict'}\n",
    "base_dir = location_dict[location_input]\n",
    "print(\"base directory is \" + base_dir)\n",
    "\n",
    "if sys.path[-1] != base_dir:\n",
    "    sys.path.append(base_dir)\n",
    "    print(\"Added \" + base_dir + \" to path: \" )\n",
    "    print(sys.path)\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"I am about to import a library\")\n",
    "from core import expression_plots \n",
    "from core import io_library \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib \n",
    "# plt.ioff()\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "data_processing_dir = base_dir + os.sep + os.path.normpath(\"expression_data\") + os.sep\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "#from sklearn import linear_model\n",
    "#import pickle\n",
    "#import subprocess\n",
    "#import networkx as nx\n",
    "# import scipy.stats as stats\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# from Bio import SeqIO\n",
    "# from Bio import SeqFeature as sf\n",
    "# from Bio.Alphabet import generic_dna\n",
    "# from Bio.Seq import Seq\n",
    "\n",
    "# import re\n",
    "\n",
    "from collections import Counter\n",
    "# import scipy.stats as stats\n",
    "# from itertools import chain\n",
    "#this only works if you are online\n",
    "online_input = input(\"are you online? Yes/No\")\n",
    "if online_input == \"Yes\": \n",
    "    import plotly.plotly as py\n",
    "    import plotly.graph_objs as pygo\n",
    "    import plotly.tools as pytools\n",
    "    py.sign_in('heineike02_student','9dMTMZgJMgUP0YX0P5mQ')\n",
    "    #py.sign_in('heineike02', 'APPjKrtARaN2ZgUYIkqr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in the KL promoter database.  \n",
    "kl_promoters = pd.read_pickle(data_processing_dir + os.path.normpath(\"kl_promoters/kl_promoters.pkl\"))\n",
    "\n",
    "#Read in the SC promoter database.  \n",
    "sc_promoters = pd.read_pickle(data_processing_dir + os.path.normpath(\"sc_promoters/sc_promoters.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load goi data from goi data file created in paralog analysis script. \n",
    "goi_data = pd.read_csv(data_processing_dir + os.sep + \"20170817_klscpka\" + os.sep + \"goi_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build enrichment sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2p0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = '2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YIL111W not in promoter data set.\n"
     ]
    }
   ],
   "source": [
    "#Upregulated v.s. all\n",
    "LFC_cutoff_high = 2.0\n",
    "genes = goi_data[goi_data['log2FoldChange_SC']>LFC_cutoff_high]['sc_genename']\n",
    "\n",
    "target_promoter_fname = data_processing_dir + os.path.normpath('sc_promoters/promoter_sets/paralogs_LFC_gt_' + str(LFC_cutoff_high).replace('.','p') + '.fasta')\n",
    "\n",
    "io_library.write_promoter_file(sc_promoters, list(genes),target_promoter_fname)\n",
    "\n",
    "#Downregulated v.s. all\n",
    "LFC_cutoff_low = -2.0\n",
    "genes = goi_data[goi_data['log2FoldChange_SC']<LFC_cutoff_high]['sc_genename']\n",
    "\n",
    "target_promoter_fname = data_processing_dir + os.path.normpath('sc_promoters/promoter_sets/paralogs_LFC_lt_' + str(LFC_cutoff_low).replace('-','m').replace('.','p') + '.fasta')\n",
    "\n",
    "io_library.write_promoter_file(sc_promoters, list(genes),target_promoter_fname)\n",
    "\n",
    "\n",
    "\n",
    "#Upregulated v.s. flat and downregulated\n",
    "#downregulated v.s. flat and upregulated\n",
    "\n",
    "all_sc_promoter_fname = data_processing_dir + os.path.normpath('sc_promoters/promoter_sets/all_sc_promoters.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run MEME to look for unbiased enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Right now meme doesn't do discriminatory and allow any number of motifs to be scanned. \n",
    "#Dreme seems to be better for that. \n",
    "#Ran GLAM2 and got a bunch of polyA sites. \n",
    "\n",
    "\n",
    "#run psp-gen to get prior for positive and negative sequences. \n",
    "psp_gen_command = ['psp-gen', '-pos', target_promoter_fname, '-neg', all_sc_promoter_fname, '-dna', \n",
    "                   '-minw', '6', #minimum width of motif\n",
    "                   '-maxw', '20', #maximum width of motif\n",
    "                   '>', 'psp_prior.psp']\n",
    "subprocess.run(psp_gen_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meme paralogs_LFC_gt_2p0.fasta -dna -oc . -nostatus -time 17358 -maxsize 60000 -mod anr -nmotifs 5 -minw 6 -maxw 50 -revcomp -psp priors.psp\n",
    "meme paralogs_LFC_gt_2p0.fasta -dna -oc . -nostatus -time 17402 -maxsize 60000 -mod zoops -nmotifs 3 -minw 6 -maxw 50 -revcomp -psp priors.psp\n",
    "dreme dreme -v 1 -oc . -dna -p paralogs_LFC_gt_2p0.fasta -n all_sc_promoters.fasta -t 18000 -e 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run FIMO for particular motifs\n",
    "#Run AME with all JASPAR motifs\n",
    "#Run exact motif matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "io_library.SC_common_name_lookup([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
