{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what computer are you on? a = Ben's laptop, b = gpucluster, c = Ben's desktop, d = otherb\n",
      "base directory is /home/heineike/github/expression_broad_data\n",
      "Added /home/heineike/github/expression_broad_data to path: \n",
      "['/home/heineike/github/expression_broad_data/scripts', '', '/home/lab/envs/seqanalysis/lib/python35.zip', '/home/lab/envs/seqanalysis/lib/python3.5', '/home/lab/envs/seqanalysis/lib/python3.5/plat-linux', '/home/lab/envs/seqanalysis/lib/python3.5/lib-dynload', '/home/lab/envs/seqanalysis/lib/python3.5/site-packages', '/home/lab/envs/seqanalysis/lib/python3.5/site-packages/argh-0.26.1-py3.5.egg', '/home/lab/envs/seqanalysis/lib/python3.5/site-packages/glob2-0.4.1-py3.5.egg', '/home/lab/envs/seqanalysis/lib/python3.5/site-packages/mmtf_python-1.0.2-py3.5.egg', '/home/lab/envs/seqanalysis/lib/python3.5/site-packages/IPython/extensions', '/home/heineike/.ipython', '/home/heineike/github/expression_broad_data']\n",
      "Importing expression plots and io_library and setting base_dir and data_processing_dir\n",
      "Importing io_library.  If autoreload, may need to reset base_dir and data_processing dir \n",
      "  io_library.base_dir=base_dir \n",
      " io_library.data_processing_dir = data_processing_dir\n",
      "are you online? Yes/No Yes\n"
     ]
    }
   ],
   "source": [
    "# %load notebook_setup.py\n",
    "#Use %load notebook_setup.py to load these commands at the top of your\n",
    "#ipython notebook.  Includes running the std_libraries.py file. \n",
    "\n",
    "%run std_libraries.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib \n",
    "# plt.ioff()\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what computer are you on? a = Ben's laptop, b = gpucluster, c = Ben's desktop, d = othera\n",
      "base directory is C:\\Users\\BMH_work\\github\\expression_broad_data\n",
      "I am about to import a library\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "are you online? Yes/No Yes\n"
     ]
    }
   ],
   "source": [
    "# # %load std_libraries.py\n",
    "# #to keep my scripts consistent, I am adding this to the top of all scripts with %load std_libraries.py\n",
    "# import sys\n",
    "# #Indicate operating environment and import core modules\n",
    "# location_input = input(\"what computer are you on? a = Ben's laptop, b = gpucluster, c = Ben's desktop, d = other\")\n",
    "# location_dict = {'a': \"C:\\\\Users\\\\BMH_work\\\\github\\\\expression_broad_data\", 'b': \"/home/heineike/github/expression_broad_data\",\n",
    "#                  'c': \"C:\\\\Users\\\\Ben\\\\Documents\\\\GitHub\\\\expression_broad_data\", 'd':'you need to add your location to the location_dict'}\n",
    "# base_dir = location_dict[location_input]\n",
    "# print(\"base directory is \" + base_dir)\n",
    "\n",
    "# if sys.path[-1] != base_dir:\n",
    "#     sys.path.append(base_dir)\n",
    "#     print(\"Added \" + base_dir + \" to path: \" )\n",
    "#     print(sys.path)\n",
    "\n",
    "# import os\n",
    "\n",
    "# print(\"I am about to import a library\")\n",
    "# from core import expression_plots \n",
    "# from core import io_library \n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# # %matplotlib \n",
    "# # plt.ioff()\n",
    "# #%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "# data_processing_dir = base_dir + os.sep + os.path.normpath(\"expression_data\") + os.sep\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# #import matplotlib.colormap as cm\n",
    "# #from matplotlib_venn import venn2\n",
    "# #for my windows10 laptop I had to install this package using pip rather than anaconda.  \n",
    "# #import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "# #from sklearn import linear_model\n",
    "# import pickle\n",
    "# #import subprocess\n",
    "# #import networkx as nx\n",
    "# #import scipy.stats as stats\n",
    "# #import statsmodels.graphics.gofplots as stats_graph\n",
    "# #import scipy.cluster.hierarchy as sch\n",
    "\n",
    "# # from Bio import SeqIO\n",
    "# # from Bio import SeqFeature as sf\n",
    "# # from Bio.Alphabet import generic_dna\n",
    "# # from Bio.Seq import Seq\n",
    "\n",
    "# # import re\n",
    "\n",
    "# from collections import Counter\n",
    "# # import scipy.stats as stats\n",
    "# # from itertools import chain\n",
    "# #from itertools import product\n",
    "# #this only works if you are online\n",
    "# online_input = input(\"are you online? Yes/No \")\n",
    "# if online_input == \"Yes\": \n",
    "#     import plotly.plotly as py\n",
    "#     import plotly.graph_objs as pygo\n",
    "#     import plotly.tools as pytools\n",
    "#     py.sign_in('heineike02_student','9dMTMZgJMgUP0YX0P5mQ')\n",
    "#     #py.sign_in('heineike02', 'APPjKrtARaN2ZgUYIkqr')\n",
    "    \n",
    "# # for phylogenetic trees: \n",
    "# # from ete3 import Tree\n",
    "# #ete3 is not officially supported on windows, and so must be loaded via pip: \n",
    "# # pip install -U https://github.com/etetoolkit/ete/archive/qt5.zip\n",
    "# # ref: https://groups.google.com/forum/#!topic/etetoolkit/6NblSBPij4o\n",
    "\n",
    "# #for scraping internet data (e.g. ncbi)\n",
    "# #import requests\n",
    "# #from lxml import etree    #parses xml output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load activated and repressed genes from \n",
    "# 20181031_klscpka_r1g1_m24_SC_analysis and\n",
    "# 20181031_klscpka_r1g1_m24_KL_analysis\n",
    "\n",
    "target_sets_dict = {}\n",
    "for spec in ['KL', 'SC']: \n",
    "    fname = data_processing_dir + '\\\\kl_sc_PKA_as_m24_r1g1_20181017\\\\20181203_r1g1_m24_pka_targets_' + spec + '.pkl'\n",
    "    \n",
    "    with open(fname, 'rb') as file:\n",
    "        target_sets_dict[spec] = pickle.load(file)\n",
    "        \n",
    "# Load Kl and SC datasets for determining background sets\n",
    "\n",
    "#Load DEseq data for SCer PKA AS -/+ NMPP1 \n",
    "pkainh_deseq_SC = pd.read_csv(os.path.normpath(data_processing_dir + '\\\\kl_sc_PKA_as_m24_r1g1_20181017\\\\20181017_deseq_SC_AS_WT_nmpp1.csv'), index_col=0)\n",
    "pkainh_deseq_SC['SC_common_name'] = io_library.SC_common_name_lookup(pkainh_deseq_SC.index)\n",
    "\n",
    "#load Deseq data for KLac AS -/+ NMPP1\n",
    "pkainh_deseq_KL = pd.read_csv(os.path.normpath(data_processing_dir + '\\\\kl_sc_PKA_as_m24_r1g1_20181017\\\\20181017_deseq_KL_AS_WT_nmpp1.csv'), index_col=0)\n",
    "pkainh_deseq_KL['kl_genename'] = io_library.kl_genename_convert_list(list(pkainh_deseq_KL.index))\n",
    "pkainh_deseq_KL.set_index('kl_genename', inplace=True)\n",
    "\n",
    "#Add column for common names\n",
    "pkainh_deseq_KL['SC_common_name'] = io_library.SC_common_name_lookup_KL(pkainh_deseq_KL.index)\n",
    "\n",
    "#Load KL to SC ortholog mapping\n",
    "\n",
    "kl_orthologs = pd.read_pickle(data_processing_dir + \"ortholog_files_YGOB/kl_orthologs.pkl\")\n",
    "\n",
    "#Set up go term list and database: \n",
    "GO_aspect = 'P'\n",
    "#The three GO_aspect are: \n",
    "#C = cellular_component\n",
    "#F = molecular_function\n",
    "#P = biological_process\n",
    "go_slims_aspect, go_term_list = io_library.load_goslim_data(GO_aspect, go_slim_fname = 'go_slim_mapping_20181204.tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Make different gene sets to look up orthologs (using SC_genenames as a key).   For SC will have all the genes, for KL will only have\n",
    "#genes with SC orthologs. \n",
    "\n",
    "#maybe making the subsets makes more sense in the KLSC analysis file\n",
    "\n",
    "gene_set_names = ['kl_only_act', 'kl_only_rep','sc_only_act','sc_only_rep','klsc_act','klsc_rep']\n",
    "\n",
    "kl_act = set(kl_orthologs.loc[kl_orthologs['kl_genename'].isin(target_sets_dict['KL'][0]['pkainh_act']),'sc_genename'])\n",
    "sc_act = target_sets_dict['SC'][0]['pkainh_act']\n",
    "kl_rep = set(kl_orthologs.loc[kl_orthologs['kl_genename'].isin(target_sets_dict['KL'][0]['pkainh_rep']),'sc_genename'])\n",
    "sc_rep = target_sets_dict['SC'][0]['pkainh_rep']\n",
    "\n",
    "gene_sets = { 'kl_only_act' : kl_act - sc_act, \n",
    "              'kl_only_rep' : kl_rep - sc_rep, \n",
    "              'sc_only_act' : sc_act - kl_act, \n",
    "              'sc_only_rep' : sc_rep - kl_rep, \n",
    "              'klsc_act' : kl_act & sc_act, \n",
    "              'klsc_rep' : kl_rep & sc_rep}\n",
    "\n",
    "background_map = {'kl_only_act' : 'KL',\n",
    "                 'kl_only_rep' : 'KL', \n",
    "                 'sc_only_act' : 'SC',\n",
    "                 'sc_only_rep': 'SC',\n",
    "                 'klsc_act': 'KL',\n",
    "                 'klsc_rep': 'KL'}\n",
    "\n",
    "background_genes = {'SC' : set(pkainh_deseq_SC.index), \n",
    "                    'KL' : set(kl_orthologs.loc[kl_orthologs['kl_genename'].isin(set(pkainh_deseq_KL.index)),'sc_genename'])}\n",
    "\n",
    "\n",
    "fname = data_processing_dir + '\\\\kl_sc_PKA_as_m24_r1g1_20181017\\\\20181204_klsc_pkainh_subsets_for_enrichment.pkl'\n",
    "\n",
    "with open(fname, 'wb') as file:\n",
    "    pickle.dump([gene_sets, background_genes, background_map], file)\n",
    "\n",
    "#Loop through + print data\n",
    "\n",
    "go_term_enrichment = {}\n",
    "pval = 0.1\n",
    "\n",
    "for gene_set_name, gene_set in gene_sets.items(): \n",
    "    go_term_enrichment_raw = io_library.go_term_enrichment(gene_set, background_genes[background_map[gene_set_name]], go_term_list, go_slims_aspect)\n",
    "    go_term_enrichment_filtered = go_term_enrichment_raw[go_term_enrichment_raw['pvalue']<pval].sort_values('pvalue')\n",
    "    go_term_enrichment[gene_set_name] = go_term_enrichment_filtered\n",
    "\n",
    "fname = data_processing_dir + \"go_terms/go_enrichment_20181204.xls\"\n",
    "writer = pd.ExcelWriter(fname)\n",
    "for gene_set_name, go_term_enrichment_set in go_term_enrichment.items(): \n",
    "    go_term_enrichment_set.to_excel(writer, sheet_name = gene_set_name)\n",
    "writer.save()\n",
    "\n",
    "#This sets a longer column width if you want to try to look at genes here rather than in the file. \n",
    "#pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table [go_enrichment]: Go term enrichment was calculated from the Go Slim Dataset [ref?] downloaded from SGD on 20180412 and p-values were calculated using fisher's exact test against a background of either all genes in S.Cerevisiae (sc_only groups) or all genes in K.Lactis that contain an SC ortholog (kl_only groups and klsc groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various gene sets\n",
    "#genes = go_term_df_cutoff.loc[\"lipid metabolic process\"]['genes common name']\n",
    "#genes = ['XBP1','RME1','COX1','COX4','COX13','COX6','GSM1','COX12','CYT1']\n",
    "#genes =  ['BAS1', 'MET32', 'GZF3','GLN3', 'MET28', 'MET4', 'GAT1'] #Purine Metabolism\n",
    "#genes = ['ADE1','ADE2','ADE4','ADE5','ADE6','ADE7','ADE8','ADE12','ADE13','ADE16']  #Purine Genes\n",
    "#genes = ['ZWF1','HIS4','SFP1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# terms_of_interest = [\"lipid metabolic process\",\"biological_process\",\"conjugation\",\"response to chemical\",\n",
    "#                      \"sporulation\",\"endosomal transport\",\"lipid transport\",\"response to oxidative stress\",\n",
    "#                      \"cellular respiration\",\"cofactor metabolic process\",\"carbohydrate transport\",\n",
    "#                      \"mitochondrial translation\", \"mitochondrion organization\",\"translational initiation\",\n",
    "#                      \"cellular amino acid metabolic process\", \"cell budding\",\n",
    "#                      \"nucleobase containing small molecule metabolic process\", \"snoRNA processing\", \"amino acid transport\"]\n",
    "\n",
    "# term_df_dict = {}\n",
    "# for term in terms_of_interest:\n",
    "#     term_genes = list(go_slims_aspect[go_slims_aspect['GO_term']==term]['sc_genename'])\n",
    "#     kl_sc_PKA_data_term = kl_sc_PKA_data[kl_sc_PKA_data['sc_genename'].isin(term_genes)]\n",
    "#     term_df_dict[term]=kl_sc_PKA_data_term\n",
    "\n",
    "# kl_sc_sig_unsig_dict = {'Unsig KL and SC' : kl_sc_PKA_data_unsig, \n",
    "#                  'Sig KL only': kl_sc_PKA_data_klsig_scunsig, \n",
    "#                  'Sig SC only': kl_sc_PKA_data_scsig_klunsig, \n",
    "#                  'Sig KL and SC': kl_sc_PKA_data_klscsig}\n",
    "\n",
    "# condition_set = {}\n",
    "# for df_dict in (term_df_dict,kl_sc_sig_unsig_dict): \n",
    "#     condition_set.update(df_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot a particular set of go terms on top of my scatter plot\n",
    "\n",
    "# #plot figure in plot.ly\n",
    "# # condition_set = {'Unsig KL and SC' : kl_sc_PKA_data_unsig, \n",
    "# #                  'Sig KL only': kl_sc_PKA_data_klsig_scunsig, \n",
    "# #                  'Sig SC only': kl_sc_PKA_data_scsig_klunsig, \n",
    "# #                  'Sig KL and SC': kl_sc_PKA_data_klscsig,\n",
    "# #                  term: kl_sc_PKA_data_term }\n",
    "\n",
    "# fig_data = [\n",
    "#   \t\t{\n",
    "#   \t\t\t'x': condition_set[condition]['PKA(AS)+1NMPP1_KL'], \n",
    "#         \t'y': condition_set[condition]['PKA(AS)+1NMPP1_SC'], \n",
    "#         \t'text': condition_set[condition]['SC_common_name'], \n",
    "#         \t'mode': 'markers', \n",
    "#         \t'name': condition} for condition in condition_set.keys()]\n",
    "# fig = {\n",
    "#     'data': fig_data,\n",
    "#     'layout': {\n",
    "#         'xaxis': {'title': 'KL LFC 4uM NMPP1'},\n",
    "#         'yaxis': {'title': 'SC LFC 4uM NMPP1'}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # IPython notebook\n",
    "# # py.iplot(fig, filename='pandas/multiple-scatter')\n",
    "\n",
    "# py.iplot(fig, filename='sc_kl_scatter_sig_highlight_20170915_various_goterms')\n",
    "\n",
    "\n",
    "# #use inline plotly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Generate a list of all genes in KL_SC_PKA_data and add as a list in intermine named\n",
    "#20170905_kl_sc_PKA_data_genes \n",
    "#We can then make subsets programmatically using the API\n",
    "\n",
    "#I ran this command: \n",
    "#\" \".join(kl_sc_PKA_data['sc_genename'])\n",
    "\n",
    "#Then copied and pasted the output into the yeastmine build query list. \n",
    "\n",
    "#The following items were not found in SGD: \n",
    "#Scer_YGOB_YDR134C Scer_RDN18-1 Scer_YGOB_SDC25 Scer_RDN25-1 Scer_RDN58-1 Scer_YGOB_Anc_7.495 Scer_YGOB_ADL119W Scer_RDN5-1\n",
    "\n",
    "#I wonder if I could do this just using something like this: query.add_constraint(\"Gene\", \"LOOKUP\", [\"YNL323W\",\"YIL093C\",...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitophagy_list = ['YCR079W','YDL113C','YFR021W','YGR049W','YIL146C','YJL036W','YLL042C','YLR423C','YNL223W','YNR007C']\n",
    "mito_disassembly_list = ['YCR079W','YDL113C','YFR021W','YGR049W','YIL146C','YJL036W','YLL042C','YLR423C','YNL223W','YNR007C']\n",
    "lipid_catabolic_list = ['YAL051W','YCR068W','YDR036C','YDR058C','YGL010W','YKR009C','YKR089C','YMR008C','YMR313C','YOL011W','YOR059C','YOR081C','YOR084W','YOR363C','YPR001W','YPR002W','YPR006C']\n",
    "#kl_sc_PKA_data[kl_sc_PKA_data['sc_genename'].isin(lipid_catabolic_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generate Query for all kl_sc_PKA_data genes\n",
    "\n",
    "# # Get a new query on the class (table) you will be querying:\n",
    "# query_all = service.new_query(\"Gene\")\n",
    "\n",
    "# # The view specifies the output columns\n",
    "# query_all.add_view(\n",
    "#     \"primaryIdentifier\", \"secondaryIdentifier\", \"organism.shortName\", \"symbol\",\n",
    "#     \"name\"\n",
    "# )\n",
    "\n",
    "# # You can edit the constraint values below\n",
    "# query_all.add_constraint(\"Gene\", \"IN\", \"20170509_kl_sc_PKA_data_genes\", code = \"A\")\n",
    "\n",
    "# # Uncomment and edit the code below to specify your own custom logic:\n",
    "# # query.set_logic(\"A\")\n",
    "\n",
    "# #gene_id_list = [str(row[\"id\"] for row in query.rows()]\n",
    "\n",
    "# #type(gene_id_list[0])\n",
    "\n",
    "# # query_list = list(query)\n",
    "\n",
    "# # for row in query_list:     #query.rows():\n",
    "# #     print(row[\"primaryIdentifier\"], row[\"secondaryIdentifier\"], row[\"organism.shortName\"], \\\n",
    "# #         row[\"symbol\"], row[\"name\"], row[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Yeastmine queries for each geneset\n",
    "# #For each set of genes\n",
    "# # gene_sets = [('klsig','act'),\n",
    "# #             ('scsig','act'),\n",
    "# #             ('klscsig','act'),\n",
    "# #             ('klsig','rep'),\n",
    "# #             ('scsig','rep'),\n",
    "# #             ('klscsig','rep')]\n",
    "\n",
    "# #Add in the one gene that is significant for both but repressed in SC and activated in KL. \n",
    "# klsig_act_genes = list(kl_sc_PKA_data_klsig_scunsig[kl_sc_PKA_data_klsig_scunsig['PKA(AS)+1NMPP1_KL']>0]['sc_genename'])\n",
    "# klsig_act_genes.append('YJL208C')\n",
    "\n",
    "# #Add in the one gene that is significant for both but activated in SC and repressed in KL.\n",
    "# klsig_rep_genes = list(kl_sc_PKA_data_klsig_scunsig[kl_sc_PKA_data_klsig_scunsig['PKA(AS)+1NMPP1_KL']<0]['sc_genename'])\n",
    "# klsig_rep_genes.append('YNL014W')\n",
    "\n",
    "# #Add in the one gene that is significant for both but activated in SC and repressed in KL.\n",
    "# scsig_act_genes = list(kl_sc_PKA_data_scsig_klunsig[kl_sc_PKA_data_scsig_klunsig['PKA(AS)+1NMPP1_SC']>0]['sc_genename'])\n",
    "# scsig_act_genes.append('YNL014W')\n",
    "\n",
    "# #Add in the one gene that is significant for both but repressed in SC and activated in KL. \n",
    "# scsig_rep_genes = list(kl_sc_PKA_data_scsig_klunsig[kl_sc_PKA_data_scsig_klunsig['PKA(AS)+1NMPP1_SC']<0]['sc_genename'])\n",
    "# scsig_rep_genes.append('YJL208C')\n",
    "\n",
    "# gene_sets = ['klsig_act', 'klsig_rep','scsig_act','scsig_rep','klscsig_act','klscsig_rep']\n",
    "\n",
    "# gene_set_dict = {'klsig_act': klsig_act_genes,\n",
    "#                  'klsig_rep': klsig_rep_genes,\n",
    "#                  'scsig_act': scsig_act_genes,\n",
    "#                  'scsig_rep': scsig_rep_genes,\n",
    "#                  'klscsig_act': list(kl_sc_PKA_data_klscsig[(kl_sc_PKA_data_klscsig['PKA(AS)+1NMPP1_SC']>0) & (kl_sc_PKA_data_klscsig['PKA(AS)+1NMPP1_KL']>0)]['sc_genename']),\n",
    "#                  'klscsig_rep': list(kl_sc_PKA_data_klscsig[(kl_sc_PKA_data_klscsig['PKA(AS)+1NMPP1_SC']<0) & (kl_sc_PKA_data_klscsig['PKA(AS)+1NMPP1_KL']<0)]['sc_genename'])\n",
    "#                 }\n",
    "\n",
    "# missing_genes = ['Scer_YGOB_YDR134C', 'Scer_RDN18-1', \n",
    "#                  'Scer_YGOB_SDC25', 'Scer_RDN25-1', \n",
    "#                  'Scer_RDN58-1', 'Scer_YGOB_Anc_7.495', \n",
    "#                  'Scer_YGOB_ADL119W', 'Scer_RDN5-1']\n",
    "\n",
    "# pval_cutoff = 0.01\n",
    "\n",
    "# for gene_set in gene_sets: \n",
    "#     print(gene_set)\n",
    "#     gene_set_list = gene_set_dict[gene_set]\n",
    "    \n",
    "#     #filter out missing genes \n",
    "#     print(\"The following missing genes are filtered out:\")\n",
    "#     print(set(gene_set_list) & set(missing_genes))\n",
    "#     gene_set_list_filtered = list(set(gene_set_list)-set(missing_genes))\n",
    "#     new_query = query_all.clone()\n",
    "    \n",
    "#     #subset query based on desired gene set\n",
    "#     new_query.add_constraint(\"Gene.secondaryIdentifier\", \"ONE OF\", gene_set_list_filtered)\n",
    "    \n",
    "#     #Generate a list\n",
    "#     new_list = service.create_list(new_query.select('Gene.id'), \"Gene\", name = \"20170905\" + gene_set)\n",
    "    \n",
    "#     #Run Go enrichment on the list\n",
    "#     results = new_list.calculate_enrichment('go_enrichment_for_gene')\n",
    "#     results_list = list(results)    \n",
    "#     for result in results_list: \n",
    "#         print(result)\n",
    "#         if result['p-value']<pval_cutoff:\n",
    "#             print(result)\n",
    "#             print(result)\n",
    "            \n",
    "#     #Given a P-value cutoff\n",
    "#     # Save the go term \n",
    "#     # Save the contingency table\n",
    "#     # Save the related genes\n",
    "\n",
    "# ##To see a list of widgets that are available\n",
    "# service.widgets \n",
    "\n",
    "#results = new_list.calculate_enrichment('go_enrichment_for_gene')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Get genes from a go term.  \n",
    "\n",
    "# from intermine.webservice import Service\n",
    "# service = Service(\"http://yeastmine.yeastgenome.org:443/yeastmine/service\")\n",
    "# query = service.new_query(\"Gene\")\n",
    "# query.add_view(\n",
    "#     \"primaryIdentifier\", \"secondaryIdentifier\", \"symbol\", \"featureType\",\n",
    "#     \"goAnnotation.qualifier\", \"goAnnotation.ontologyTerm.identifier\",\n",
    "#     \"goAnnotation.ontologyTerm.name\", \"goAnnotation.ontologyTerm.namespace\",\n",
    "#     \"goAnnotation.evidence.code.code\", \"goAnnotation.evidence.code.withText\",\n",
    "#     \"goAnnotation.evidence.code.annotType\",\n",
    "#     \"goAnnotation.evidence.publications.pubMedId\",\n",
    "#     \"goAnnotation.evidence.publications.citation\"\n",
    "# )\n",
    "# query.add_sort_order(\"Gene.secondaryIdentifier\", \"ASC\")\n",
    "# query.add_constraint(\"goAnnotation.ontologyTerm\", \"LOOKUP\", \"GO:0000182\", code = \"A\")\n",
    "\n",
    "# for row in query.rows():\n",
    "#     print row[\"primaryIdentifier\"], row[\"secondaryIdentifier\"], row[\"symbol\"], row[\"featureType\"], \\\n",
    "#         row[\"goAnnotation.qualifier\"], row[\"goAnnotation.ontologyTerm.identifier\"], \\\n",
    "#         row[\"goAnnotation.ontologyTerm.name\"], row[\"goAnnotation.ontologyTerm.namespace\"], \\\n",
    "#         row[\"goAnnotation.evidence.code.code\"], row[\"goAnnotation.evidence.code.withText\"], \\\n",
    "#         row[\"goAnnotation.evidence.code.annotType\"], \\\n",
    "#         row[\"goAnnotation.evidence.publications.pubMedId\"], \\\n",
    "#         row[\"goAnnotation.evidence.publications.citation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #See which genes correspond to JSO targets. \n",
    "# jso_msn2_targets = ['SSA1', 'SSA4', 'HSP104', 'CTT1', 'TPK1', 'TFS1', 'DDR2', 'TSA1', 'HSP12', 'TMA10', 'TPS2', 'RTC3', 'GPH1', 'HXK1', 'TSA2', 'CYC7', 'PNC1', 'GSY1', 'FMP48', 'SS13', 'ALD4', 'YNR014W', 'HOR2', 'YOR173W', 'RAS2', 'GLK1', 'GPD1', 'HSP26', 'SIP18', 'TKL2', 'FMP16', 'ALD3', 'PGM2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_set_data = kl_sc_PKA_data[kl_sc_PKA_data['SC_common_name'].isin(jso_msn2_targets)]\n",
    "# gene_set_list = gene_set_data['sc_genename']\n",
    "\n",
    "\n",
    "# go_term_data = []\n",
    "\n",
    "# go_term_index = []\n",
    "\n",
    "# for term in go_term_list: \n",
    "#     term_genes = list(go_slims_aspect[go_slims_aspect['GO_term']==term]['sc_genename'])\n",
    "#     if len(term_genes)> len(set(term_genes)):\n",
    "#         print(\"Duplicate Term: \" + term)\n",
    "#     subset_genes_in_goterm =  set(gene_set_list) & set(term_genes)\n",
    "#     N_subset_genes_in_goterm = len(subset_genes_in_goterm)\n",
    "#     N_genes_in_goterm = len(term_genes)\n",
    "#     if N_subset_genes_in_goterm >0:\n",
    "#         subset_genes_in_goterm_commonname = io_library.SC_common_name_lookup(subset_genes_in_goterm)\n",
    "#         go_term_data.append((N_subset_genes_in_goterm,\n",
    "#                              subset_genes_in_goterm,\n",
    "#                              subset_genes_in_goterm_commonname,\n",
    "#                              N_genes_in_goterm))\n",
    "#         go_term_index.append(term)\n",
    "\n",
    "# go_term_df = pd.DataFrame(go_term_data, index = go_term_index,columns = ['N subset genes in goterm',\n",
    "#                                                                             'genes',\n",
    "#                                                                             'genes common name',\n",
    "#                                                                             'N genes in goterm'])\n",
    "# go_term_df[['genes common name','N genes in goterm']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seqanalysis",
   "language": "python",
   "name": "seqanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
