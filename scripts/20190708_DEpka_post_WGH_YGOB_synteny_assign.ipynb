{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing io_library.  If autoreload, may need to reset base_dir and data_processing dir \n",
      "  io_library.base_dir=base_dir \n",
      " io_library.data_processing_dir = data_processing_dir\n",
      "what computer are you on? a = Ben's laptop, b = gpucluster, c = Ben's desktop, d = otherb\n",
      "base directory is /home/heineike/github/expression_broad_data\n",
      "Importing expression plots and io_library and setting base_dir and data_processing_dir\n",
      "are you online? Yes/No Yes\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %load notebook_setup.py\n",
    "#Use %load notebook_setup.py to load these commands at the top of your\n",
    "#ipython notebook.  Includes running the std_libraries.py file. \n",
    "\n",
    "%run std_libraries.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib \n",
    "# plt.ioff()\n",
    "#%matplotlib inline\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load GOI ohnolog data\n",
    "fname = data_processing_dir + os.sep + os.path.normpath('kl_sc_PKA_as_m24_r1g1_20181017/gois_20181205.pkl')\n",
    "\n",
    "with open(fname, 'rb') as file:\n",
    "    [ohnologs_goi,ohnologs_expression_sorted,goi_criteria] = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract files using url\n",
    "window = '8'\n",
    "\n",
    "pillars_goi_fname = os.path.normpath(data_processing_dir + \"ortholog_files_YGOB/YGOB_pillars_goi.txt\")\n",
    "\n",
    "with open(pillars_goi_fname,'w') as f:\n",
    "    for anc in ohnologs_goi['Ancestor']:\n",
    "\n",
    "        YGOB_query_url = 'http://ygob.ucd.ie/cgi/browser/tab.pl?ver=Latest&win=' + window + '&gene=' + anc\n",
    "        YGOB_query_response = requests.get(YGOB_query_url)\n",
    "\n",
    "        soup = BeautifulSoup(YGOB_query_response.text)\n",
    "        table = soup.find(\"table\")\n",
    "\n",
    "        output_rows = []\n",
    "        for table_row in table.findAll('tr'):\n",
    "            columns = table_row.findAll('td')\n",
    "            output_row = []\n",
    "            for column in columns:\n",
    "                output_row.append(column.text)\n",
    "            output_rows.append(output_row)\n",
    "\n",
    "        synteny_window = pd.DataFrame(output_rows[2:],columns = output_rows[1])\n",
    "        synteny_row = synteny_window[synteny_window['Ancestor']==anc]\n",
    "        print(\"\\t\".join(synteny_row.iloc[0,:].values) + '\\n')\n",
    "        f.write(\"\\t\".join(synteny_row.iloc[0,:].values) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Ndai-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Vpol-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Kafr-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Knag-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Cgla-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Scer-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Tbla-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Ncas-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Skud-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Smik-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Tpha-goi-orthologs.txt\n",
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Suva-goi-orthologs.txt\n"
     ]
    }
   ],
   "source": [
    "#Build ortholog mapping from S.Cer to post WGH species for gois\n",
    "spec_order_post_WGH = ['Scer','Smik','Skud','Suva', 'Cgla', 'Kafr','Knag','Ndai','Ncas','Tbla','Tpha','Vpol'] \n",
    "\n",
    "spec1 = 'Scer'\n",
    "for spec2 in list(set(spec_order_post_WGH)-set(spec1)):\n",
    "    io_library.write_YGOB_orth_lookup_table_goi(spec1,spec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/heineike/github/expression_broad_data/expression_data/ortholog_files_YGOB/Scer-Smik-goi-orthologs.txt\n"
     ]
    }
   ],
   "source": [
    "spec1= 'Scer'\n",
    "spec2= 'Smik'\n",
    "#def write_YGOB_orth_lookup_table_goi(spec1, spec2):\n",
    "#This is necessary because pillars does not specify syntenic assignment for post-WGH genes\n",
    "#uses data generated from YGOB in 20190708_DEpka_post_WGH_YGOB_synteny_assign\n",
    "\n",
    "#Makes an orhtolog lookup table for all species in the YGOB Pillars data for just goi\n",
    "#spec1 the index, spec2 is the lookup.  multiple orthologs separated by tabs, NONE if there are none.  \n",
    "\n",
    "#Note that this cannot lookup Small Scale Duplications after the WGH because that data is not part of the pillars \n",
    "\n",
    "fname = os.path.normpath(data_processing_dir + \"ortholog_files_YGOB/YGOB_pillars_goi.txt\")\n",
    "\n",
    "    #YGOB_Pillars.txt order of species: \n",
    "    #    0    V. polyspora Position B\n",
    "    #    1    T. phaffii Position B\n",
    "    #    2    T. blattae Position B\n",
    "    #    3    N. dairenensis Position B\n",
    "    #    4    N. castellii Position B\n",
    "    #    5    K. naganishii Position B\n",
    "    #    6    K. africana Position B\n",
    "    #    7    C. glabrata Position B\n",
    "    #    8    S. bayanus var. uvarum Position B\n",
    "    #    9    S. kudriavzevii Position B\n",
    "    #    10   S. mikatae Position B\n",
    "    #    11   S. cerevisiae Position B\n",
    "    #    12   L. waltii\n",
    "    #    13   L. thermotolerans\n",
    "    #    14   L. kluyveri\n",
    "    #    15   E. cymbalariae\n",
    "    #    16   E. gossypii \n",
    "    #    17   K. lactis\n",
    "    #    18   T. delbrueckii\n",
    "    #    19   Z. rouxii\n",
    "    #    20   Ancestral Gene Order\n",
    "    #    21   S. cerevisiae Position A\n",
    "    #    22   S. mikatae Position A\n",
    "    #    23   S. kudriavzevii Position A\n",
    "    #    24   S. bayanus var. uvarum Position A\n",
    "    #    25   C. glabrata Position A\n",
    "    #    26   K. africana Position A\n",
    "    #    27   K. naganishii Position A\n",
    "    #    28   N. castellii Position A\n",
    "    #    29   N. dairenensis Position A\n",
    "    #    30   T. blattae Position A\n",
    "    #    31   T. phaffii Position A\n",
    "    #    32   V. polyspora Position A\n",
    "\n",
    "    #position in pillars file of ancestor\n",
    "    #anc_pos = 20\n",
    "\n",
    "    #for regev lab expression data, Suva and Sbay have same gene names. \n",
    "    orth_positions_post_WGH = {'Vpol': [0,32], 'Tpha': [1,31], 'Tbla': [2,30], 'Ndai': [3,29], \n",
    "                      'Ncas': [4,28], 'Knag': [5,27], 'Kafr': [6,26], 'Cgla': [7,25],\n",
    "                      'Suva': [8,24], 'Sbay':[8,24], 'Skud': [9,23], 'Smik': [10,22], 'Scer' : [11,21]}\n",
    "\n",
    "\n",
    "    orth_positions_pre_WGH = {'Zrou':19, 'Tdel':18, 'Klac':17, 'Egos':16, 'Ecym': 15, 'Lklu':14, 'Lthe':13, 'Lwal':12}\n",
    "\n",
    "    #Case1: spec1 post WGH, spec2 pre WGH\n",
    "\n",
    "    if ((spec1 in orth_positions_post_WGH.keys()) & (spec2 in orth_positions_pre_WGH.keys())): \n",
    "        spec1_columns = orth_positions_post_WGH[spec1]\n",
    "        spec2_column = orth_positions_pre_WGH[spec2]\n",
    "\n",
    "        with open(fname) as f:\n",
    "            orth_lookup = {}\n",
    "            for line in f:\n",
    "                linesp = line.split()\n",
    "                for spec1_column in spec1_columns: \n",
    "                    spec1_gene = linesp[spec1_column]\n",
    "                    if spec1_gene!= '---':\n",
    "                        spec2_gene = linesp[spec2_column]\n",
    "                        if spec2_gene!='---': \n",
    "                            orth_lookup[spec1_gene] = spec2_gene\n",
    "                        else: \n",
    "                            orth_lookup[spec1_gene] = 'NONE'\n",
    "\n",
    "    #Case2: spec1 pre WGH, spec2 pre WGH\n",
    "\n",
    "    if ((spec1 in orth_positions_pre_WGH.keys()) & (spec2 in orth_positions_pre_WGH.keys())): \n",
    "        spec1_column = orth_positions_pre_WGH[spec1]\n",
    "        spec2_column = orth_positions_pre_WGH[spec2]\n",
    "\n",
    "        with open(fname) as f:\n",
    "            orth_lookup = {}\n",
    "            for line in f:\n",
    "                linesp = line.split()\n",
    "                spec1_gene = linesp[spec1_column]\n",
    "                if spec1_gene!= '---':\n",
    "                    spec2_gene = linesp[spec2_column]\n",
    "                    if spec2_gene!='---': \n",
    "                        orth_lookup[spec1_gene] = spec2_gene\n",
    "                    else: \n",
    "                        orth_lookup[spec1_gene] = 'NONE'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Case 3: spec1 pre WGH, spec2 post WGH\n",
    "    #In this case there will often be more than one ortholog per pre WGH gene\n",
    "\n",
    "    if ((spec1 in orth_positions_pre_WGH.keys()) & (spec2 in orth_positions_post_WGH.keys())): \n",
    "        spec1_column = orth_positions_pre_WGH[spec1]\n",
    "        spec2_columns = orth_positions_post_WGH[spec2]\n",
    "\n",
    "        with open(fname) as f:\n",
    "            orth_lookup = {}\n",
    "            for line in f:\n",
    "                linesp = line.split()\n",
    "                spec1_gene = linesp[spec1_column]\n",
    "                if spec1_gene!= '---':\n",
    "                    spec2_genes = []\n",
    "                    for spec2_column in spec2_columns: \n",
    "                        spec2_gene = linesp[spec2_column]\n",
    "                        if spec2_gene!='---':\n",
    "                            spec2_genes.append(spec2_gene)\n",
    "                    if len(spec2_genes)==0:\n",
    "                        orth_lookup[spec1_gene] = 'NONE'\n",
    "                    else: \n",
    "                        orth_lookup[spec1_gene] = spec2_genes\n",
    "\n",
    "\n",
    "    #Case 4: spec1 pre WGH, spec2 pre WGH\n",
    "    #use tracks in pillars file to match up WGH genes.  If there are two paralogs, this will match tracks. \n",
    "    #If there is one paralog, and there are two orthologs, it will list both.  \n",
    "    #If there is only one ortholog for one gene, it will list the other one regardless of track.  \n",
    "\n",
    "    if ((spec1 in orth_positions_post_WGH.keys()) & (spec2 in orth_positions_post_WGH.keys())): \n",
    "        spec1_columns = orth_positions_post_WGH[spec1]\n",
    "        spec2_columns = orth_positions_post_WGH[spec2]\n",
    "\n",
    "        with open(fname) as f:\n",
    "            orth_lookup = {}\n",
    "            for line in f:\n",
    "                linesp = line.split()\n",
    "                spec1_genes = []\n",
    "                for spec1_column in spec1_columns: \n",
    "                    spec1_gene = linesp[spec1_column]\n",
    "                    if spec1_gene!= '---':\n",
    "                        spec1_genes.append(spec1_gene)\n",
    "\n",
    "                if len(spec1_genes)==2: \n",
    "                    for jj,spec1_gene in enumerate(spec1_genes): \n",
    "                        spec2_column = spec2_columns[jj]\n",
    "                        spec2_gene = linesp[spec2_column]\n",
    "                        if spec2_gene!='---':\n",
    "                            orth_lookup[spec1_gene] = [spec2_gene]\n",
    "                        else: \n",
    "                            orth_lookup[spec1_gene] = ['NONE']\n",
    "\n",
    "                elif len(spec1_genes)==1: \n",
    "                    spec1_gene = spec1_genes[0]\n",
    "                    spec2_genes = []\n",
    "                    for spec2_column in spec2_columns: \n",
    "                        spec2_gene = linesp[spec2_column]\n",
    "                        if spec2_gene!='---':\n",
    "                            spec2_genes.append(spec2_gene)\n",
    "                    if len(spec2_genes)==0:\n",
    "                        orth_lookup[spec1_gene] = 'NONE'\n",
    "                    else: \n",
    "                        orth_lookup[spec1_gene] = spec2_genes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    orth_lookup_outputfname = os.path.normpath(data_processing_dir + 'ortholog_files_YGOB/' + spec1 + \"-\" + spec2 + \"-goi-orthologs.txt\"  )\n",
    "\n",
    "    print(orth_lookup_outputfname)\n",
    "    io_library.print_ortholog_file(orth_lookup_outputfname, orth_lookup)\n",
    "\n",
    "    return orth_lookup "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seqanalysis",
   "language": "python",
   "name": "seqanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
